{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](img/330-banner.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Lecture 5: Preprocessing and `sklearn` pipelines\n",
    "\n",
    "UBC 2020-21\n",
    "\n",
    "Instructor: Varada Kolhatkar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import HTML\n",
    "\n",
    "sys.path.append(\"code/.\")\n",
    "\n",
    "import mglearn\n",
    "from IPython.display import display\n",
    "from plotting_functions import *\n",
    "\n",
    "# Classifiers and regressors\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "\n",
    "# Preprocessing and pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# train test split and cross validation\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import (\n",
    "    MinMaxScaler,\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    "    StandardScaler,\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from utils import *\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Announcements\n",
    "- Homework 3 is out. (Due date: Oct 4th.) Please start early. \n",
    "- We're mostly done with Homework 1 grading. The grades will be released either today  or tomorrow morning. \n",
    "- Homework 2 solutions are posted on Canvas. Please do not share them with anyone or do not post them anywhere. \n",
    "- No homework pull requests, please. \n",
    "- Morale poll\n",
    "    - ~82% of you are doing OK but ~18% of you are feeling overwhelmed ðŸ˜”.\n",
    "    - Please reach out and make use of tutorials and office hours if you are struggling.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Learning outcomes\n",
    "\n",
    "From this lecture, you will be able to \n",
    "\n",
    "- explain motivation for preprocessing in supervised machine learning;\n",
    "- identify when to implement feature transformations such as imputation, scaling, and one-hot encoding in a machine learning model development pipeline; \n",
    "- use `sklearn` transformers for applying feature transformations on your dataset;\n",
    "- discuss golden rule in the context of feature transformations;\n",
    "- use `sklearn.pipeline.Pipeline` and `sklearn.pipeline.make_pipeline` to build a preliminary machine learning pipeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Motivation and big picture [[video](https://youtu.be/xx9HlmzORRk)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- So far we have seen\n",
    "    - Three ML models (decision trees, $k$-NNs, SVMs with RBF kernel)\n",
    "    - ML fundamentals (train-validation-test split, cross-validation, the fundamental tradeoff, the golden rule)\n",
    "- Are we ready to do machine learning on real-world datasets?\n",
    "    - Very often real-world datasets need preprocessing before we use them to build ML models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: $k$-nearest neighbours on the Spotify dataset\n",
    "\n",
    "- In lab1 you used `DecisionTreeClassifier` to predict whether the user would like a particular song or not. \n",
    "- Can we use $k$-NN classifier for this task? \n",
    "- Intuition: To predict whether the user likes a particular song or not (query point) \n",
    "   - find the songs that are closest to the query point\n",
    "   - let them vote on the target\n",
    "   - take the majority vote as the target for the query point\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "spotify_df = pd.read_csv(\"data/spotify.csv\", index_col=0)\n",
    "train_df, test_df = train_test_split(spotify_df, test_size=0.20, random_state=123)\n",
    "X_train, y_train = (\n",
    "    train_df.drop(columns=[\"song_title\", \"artist\", \"target\"]),\n",
    "    train_df[\"target\"],\n",
    ")\n",
    "X_test, y_test = (\n",
    "    test_df.drop(columns=[\"song_title\", \"artist\", \"target\"]),\n",
    "    test_df[\"target\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean validation score 0.508\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000645</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.507740</td>\n",
       "      <td>0.507752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.507740</td>\n",
       "      <td>0.507752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.507740</td>\n",
       "      <td>0.507752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.506211</td>\n",
       "      <td>0.508133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.509317</td>\n",
       "      <td>0.507359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  0.000645    0.000255    0.507740     0.507752\n",
       "1  0.000482    0.000197    0.507740     0.507752\n",
       "2  0.000454    0.000193    0.507740     0.507752\n",
       "3  0.000450    0.000195    0.506211     0.508133\n",
       "4  0.000451    0.000191    0.509317     0.507359"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "scores = cross_validate(dummy, X_train, y_train, return_train_score=True)\n",
    "print(\"Mean validation score %0.3f\" % (np.mean(scores[\"test_score\"])))\n",
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean validation score 0.546\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002364</td>\n",
       "      <td>0.008063</td>\n",
       "      <td>0.563467</td>\n",
       "      <td>0.717829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002073</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.535604</td>\n",
       "      <td>0.721705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001917</td>\n",
       "      <td>0.007408</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.708527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001993</td>\n",
       "      <td>0.007992</td>\n",
       "      <td>0.537267</td>\n",
       "      <td>0.721921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001837</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.562112</td>\n",
       "      <td>0.711077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  0.002364    0.008063    0.563467     0.717829\n",
       "1  0.002073    0.007181    0.535604     0.721705\n",
       "2  0.001917    0.007408    0.529412     0.708527\n",
       "3  0.001993    0.007992    0.537267     0.721921\n",
       "4  0.001837    0.007380    0.562112     0.711077"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "scores = cross_validate(knn, X_train, y_train, return_train_score=True)\n",
    "print(\"Mean validation score %0.3f\" % (np.mean(scores[\"test_score\"])))\n",
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>0.229000</td>\n",
       "      <td>0.494</td>\n",
       "      <td>147893</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0469</td>\n",
       "      <td>-9.743</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>140.832</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.771</td>\n",
       "      <td>227143</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.602000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5950</td>\n",
       "      <td>-4.712</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>111.959</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     acousticness  danceability  duration_ms  energy  instrumentalness  key  \\\n",
       "842      0.229000         0.494       147893   0.666          0.000057    9   \n",
       "654      0.000289         0.771       227143   0.949          0.602000    8   \n",
       "\n",
       "     liveness  loudness  mode  speechiness    tempo  time_signature  valence  \n",
       "842    0.0469    -9.743     0       0.0351  140.832             4.0    0.704  \n",
       "654    0.5950    -4.712     1       0.1750  111.959             4.0    0.372  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_songs = X_train.sample(2, random_state=42)\n",
    "two_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0.        , 79250.00543825],\n",
       "       [79250.00543825,     0.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_distances(two_songs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider only two features: `duration_ms` and `tempo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>tempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>147893</td>\n",
       "      <td>140.832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>227143</td>\n",
       "      <td>111.959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     duration_ms    tempo\n",
       "842       147893  140.832\n",
       "654       227143  111.959"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_songs_subset = two_songs[[\"duration_ms\", \"tempo\"]]\n",
    "two_songs_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0.        , 79250.00525962],\n",
       "       [79250.00525962,     0.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_distances(two_songs_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see any problem? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- The distance is completely dominated by the the features with larger values\n",
    "- The features with smaller values are being ignored. \n",
    "- Does it matter? \n",
    "    - Yes! Scale is based on how data was collected. \n",
    "    - Features on a smaller scale can be highly informative and there is no good reason to ignore them.\n",
    "    - We want our model to be robust and not sensitive to the scale. \n",
    "- Was this a problem for decision trees?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scaling using `scikit-learn`'s [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n",
    "\n",
    "- We'll use `scikit-learn`'s [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html), which is a `transformer`.   \n",
    "- Only focus on the syntax for now. We'll talk about scaling in a bit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.697633</td>\n",
       "      <td>-0.194548</td>\n",
       "      <td>-0.398940</td>\n",
       "      <td>-0.318116</td>\n",
       "      <td>-0.492359</td>\n",
       "      <td>1.275623</td>\n",
       "      <td>-0.737898</td>\n",
       "      <td>0.395794</td>\n",
       "      <td>-1.280599</td>\n",
       "      <td>-0.617752</td>\n",
       "      <td>-0.293827</td>\n",
       "      <td>0.138514</td>\n",
       "      <td>-0.908149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.276291</td>\n",
       "      <td>0.295726</td>\n",
       "      <td>-0.374443</td>\n",
       "      <td>-0.795552</td>\n",
       "      <td>0.598355</td>\n",
       "      <td>-1.487342</td>\n",
       "      <td>-0.438792</td>\n",
       "      <td>-0.052394</td>\n",
       "      <td>0.780884</td>\n",
       "      <td>2.728394</td>\n",
       "      <td>-0.802595</td>\n",
       "      <td>-3.781179</td>\n",
       "      <td>-1.861238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.599540</td>\n",
       "      <td>1.110806</td>\n",
       "      <td>-0.376205</td>\n",
       "      <td>-0.946819</td>\n",
       "      <td>-0.492917</td>\n",
       "      <td>0.446734</td>\n",
       "      <td>-0.399607</td>\n",
       "      <td>-0.879457</td>\n",
       "      <td>0.780884</td>\n",
       "      <td>2.534909</td>\n",
       "      <td>0.191274</td>\n",
       "      <td>0.138514</td>\n",
       "      <td>0.575870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.307150</td>\n",
       "      <td>1.809445</td>\n",
       "      <td>-0.654016</td>\n",
       "      <td>-1.722063</td>\n",
       "      <td>-0.492168</td>\n",
       "      <td>0.170437</td>\n",
       "      <td>-0.763368</td>\n",
       "      <td>-1.460798</td>\n",
       "      <td>-1.280599</td>\n",
       "      <td>-0.608647</td>\n",
       "      <td>-0.839616</td>\n",
       "      <td>0.138514</td>\n",
       "      <td>1.825358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.634642</td>\n",
       "      <td>0.491835</td>\n",
       "      <td>-0.131344</td>\n",
       "      <td>1.057468</td>\n",
       "      <td>2.723273</td>\n",
       "      <td>0.170437</td>\n",
       "      <td>-0.458384</td>\n",
       "      <td>-0.175645</td>\n",
       "      <td>-1.280599</td>\n",
       "      <td>-0.653035</td>\n",
       "      <td>-0.074294</td>\n",
       "      <td>0.138514</td>\n",
       "      <td>-0.754491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness  danceability  duration_ms    energy  instrumentalness  \\\n",
       "0     -0.697633     -0.194548    -0.398940 -0.318116         -0.492359   \n",
       "1     -0.276291      0.295726    -0.374443 -0.795552          0.598355   \n",
       "2     -0.599540      1.110806    -0.376205 -0.946819         -0.492917   \n",
       "3     -0.307150      1.809445    -0.654016 -1.722063         -0.492168   \n",
       "4     -0.634642      0.491835    -0.131344  1.057468          2.723273   \n",
       "\n",
       "        key  liveness  loudness      mode  speechiness     tempo  \\\n",
       "0  1.275623 -0.737898  0.395794 -1.280599    -0.617752 -0.293827   \n",
       "1 -1.487342 -0.438792 -0.052394  0.780884     2.728394 -0.802595   \n",
       "2  0.446734 -0.399607 -0.879457  0.780884     2.534909  0.191274   \n",
       "3  0.170437 -0.763368 -1.460798 -1.280599    -0.608647 -0.839616   \n",
       "4  0.170437 -0.458384 -0.175645 -1.280599    -0.653035 -0.074294   \n",
       "\n",
       "   time_signature   valence  \n",
       "0        0.138514 -0.908149  \n",
       "1       -3.781179 -1.861238  \n",
       "2        0.138514  0.575870  \n",
       "3        0.138514  1.825358  \n",
       "4        0.138514 -0.754491  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()  # create feature trasformer object\n",
    "scaler.fit(X_train)  # fitting the transformer on the train split\n",
    "X_train_scaled = scaler.transform(X_train)  # transforming the train split\n",
    "X_test_scaled = scaler.transform(X_test)  # transforming the test split\n",
    "pd.DataFrame(X_train_scaled, columns=X_train.columns).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `fit` and `transform` paradigm for transformers\n",
    "- `sklearn` uses `fit` and `transform` paradigms for feature transformations. \n",
    "- We `fit` the transformer on the train split and then transform the train split as well as the test split. \n",
    "- We apply the same transformations on the test split. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `sklearn` API summary: estimators\n",
    "\n",
    "Suppose `model` is a classification or regression model. \n",
    "\n",
    "```\n",
    "model.fit(X_train, y_train)\n",
    "X_train_predictions = model.predict(X_train)\n",
    "X_test_predictions = model.predict(X_test)\n",
    "```    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `sklearn` API summary: transformers\n",
    "\n",
    "Suppose `transformer` is a transformer used to change the input representation, for example, to tackle missing values or to scales numeric features.\n",
    "\n",
    "```\n",
    "transformer.fit(X_train, [y_train])\n",
    "X_train_transformed = transformer.transform(X_train)\n",
    "X_test_transformed = transformer.transform(X_test)\n",
    "```  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- You can pass `y_train` in `fit` but it's usually ignored. It allows you to pass it just to be consistent with usual usage of `sklearn`'s `fit` method.   \n",
    "- You can also carry out fitting and transforming in one call using `fit_transform`. But be mindful to use it only on the train split and **not** on the test split. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Do you expect `DummyClassifier` results to change after scaling the data? \n",
    "- Let's check whether scaling makes any difference for $k$-NNs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.726\n",
      "Test score: 0.552\n"
     ]
    }
   ],
   "source": [
    "knn_unscaled = KNeighborsClassifier()\n",
    "knn_unscaled.fit(X_train, y_train)\n",
    "print(\"Train score: %0.3f\" % (knn_unscaled.score(X_train, y_train)))\n",
    "print(\"Test score: %0.3f\" % (knn_unscaled.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.798\n",
      "Test score: 0.686\n"
     ]
    }
   ],
   "source": [
    "knn_scaled = KNeighborsClassifier()\n",
    "knn_scaled.fit(X_train_scaled, y_train)\n",
    "print(\"Train score: %0.3f\" % (knn_scaled.score(X_train_scaled, y_train)))\n",
    "print(\"Test score: %0.3f\" % (knn_scaled.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- The scores with scaled data are better compared to the unscaled data in case of $k$-NNs.\n",
    "- I am not carrying out cross-validation here for a reason that we'll look into soon. \n",
    "- Note that I am a bit sloppy here and using the test set several times for teaching purposes. But when you build an ML pipeline, please do assessment on the test set only once.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Common preprocessing techniques\n",
    "\n",
    "Some commonly performed feature transformation include:  \n",
    "- Imputation: Tackling missing values\n",
    "- Scaling: Scaling of numeric features\n",
    "- One-hot encoding: Tackling categorical variables      \n",
    "    \n",
    "\n",
    "We can have one lecture on each of them! In this lesson our goal is to getting familiar with them so that we can use them to build ML pipelines. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the next part of this lecture, we'll build an ML pipeline using [California housing prices regression dataset](https://www.kaggle.com/harrywang/housing). In the process, we will talk about different feature transformations and how can we apply them so that we do not violate the golden rule. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:cpsc330]",
   "language": "python",
   "name": "conda-env-cpsc330-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
